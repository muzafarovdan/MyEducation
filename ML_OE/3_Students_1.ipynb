{"cells":[{"cell_type":"markdown","metadata":{"id":"TAyzWDzFdnLa"},"source":["## Классификация текстов: Spam or Ham"]},{"cell_type":"markdown","metadata":{"id":"sh91cKPmdnLb"},"source":["В этом задании на примере классического датасета Spambase Dataset (https://archive.ics.uci.edu/ml/datasets/spambase) мы попробуем сделать свой спам-фильтр c помощью библиотеки scikit-learn. Датасет содержит корпус текстов 5,574 смс с метками \"spam\" и \"ham\". "]},{"cell_type":"markdown","metadata":{"id":"D4Bf-AmgdnLb"},"source":["### Данные"]},{"cell_type":"markdown","metadata":{"id":"lWvXDXKrdnLb"},"source":["Для удобства данные приложены в описании задания"]},{"cell_type":"code","execution_count":260,"metadata":{"id":"UnJwvQzbdnLb"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv('3_data.csv', encoding='latin-1')"]},{"cell_type":"code","execution_count":261,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","      <th>Unnamed: 2</th>\n","      <th>Unnamed: 3</th>\n","      <th>Unnamed: 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5567</th>\n","      <td>spam</td>\n","      <td>This is the 2nd time we have tried 2 contact u...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5568</th>\n","      <td>ham</td>\n","      <td>Will Ì_ b going to esplanade fr home?</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5569</th>\n","      <td>ham</td>\n","      <td>Pity, * was in mood for that. So...any other s...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5570</th>\n","      <td>ham</td>\n","      <td>The guy did some bitching but I acted like i'd...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5571</th>\n","      <td>ham</td>\n","      <td>Rofl. Its true to its name</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5572 rows × 5 columns</p>\n","</div>"],"text/plain":["        v1                                                 v2 Unnamed: 2  \\\n","0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n","1      ham                      Ok lar... Joking wif u oni...        NaN   \n","2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n","3      ham  U dun say so early hor... U c already then say...        NaN   \n","4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n","...    ...                                                ...        ...   \n","5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n","5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n","5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n","5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n","5571   ham                         Rofl. Its true to its name        NaN   \n","\n","     Unnamed: 3 Unnamed: 4  \n","0           NaN        NaN  \n","1           NaN        NaN  \n","2           NaN        NaN  \n","3           NaN        NaN  \n","4           NaN        NaN  \n","...         ...        ...  \n","5567        NaN        NaN  \n","5568        NaN        NaN  \n","5569        NaN        NaN  \n","5570        NaN        NaN  \n","5571        NaN        NaN  \n","\n","[5572 rows x 5 columns]"]},"execution_count":261,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{"id":"GRqzedIIdnLc"},"source":["Оставляем только интересующие нас колонки — тексты смс и метки:"]},{"cell_type":"code","execution_count":262,"metadata":{"id":"xO59-HEadnLc","outputId":"470c6b7d-6e6f-4105-eab4-947debd213ef"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  label                                               text\n","0   ham  Go until jurong point, crazy.. Available only ...\n","1   ham                      Ok lar... Joking wif u oni...\n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3   ham  U dun say so early hor... U c already then say...\n","4   ham  Nah I don't think he goes to usf, he lives aro..."]},"execution_count":262,"metadata":{},"output_type":"execute_result"}],"source":["df = df[['v1', 'v2']]\n","df = df.rename(columns = {'v1': 'label', 'v2': 'text'})\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"NU2xwmvIdnLd"},"source":["Удаляем дублирующиеся тексты:"]},{"cell_type":"code","execution_count":263,"metadata":{"id":"iveCG_bXdnLd"},"outputs":[],"source":["df = df.drop_duplicates('text')"]},{"cell_type":"markdown","metadata":{"id":"XuPip3mzdnLd"},"source":["Заменяем метки на бинарные:"]},{"cell_type":"code","execution_count":264,"metadata":{"id":"JsKdfy6-dnLd"},"outputs":[],"source":["df['label'] = df['label'].map({'ham': 0, 'spam': 1})"]},{"cell_type":"markdown","metadata":{"id":"8vQJK8LNdnLe"},"source":["### Предобработка текста (Задание 1)"]},{"cell_type":"markdown","metadata":{"id":"D8tefVdTdnLe"},"source":["Нужно дополнить функцию для предобработки сообщений, которая делает с текстом следующее:\n","* приводит текст к нижнему регистру;\n","* удаляет стоп-слова;\n","* удаляет знаки препинания;\n","* нормализует текст при помощи стеммера Snowball.\n","\n","Предлагаем воспользоваться библиотекой nltk, чтобы не составлять список стоп-слов и не реализовывать алгоритм стемминга самостоятельно. Примеры использования стеммеров можно найти по ссылке (https://www.nltk.org/howto/stem.html)."]},{"cell_type":"code","execution_count":265,"metadata":{},"outputs":[{"data":{"text/plain":["'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"]},"execution_count":265,"metadata":{},"output_type":"execute_result"}],"source":["df['text'][0]"]},{"cell_type":"code","execution_count":266,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["go jurong point crazi avail bugi n great world la e buffet cine got amor wat\n"]}],"source":["from nltk import stem\n","from nltk.corpus import stopwords\n","import re\n","import string \n","\n","stemmer = stem.SnowballStemmer('english')\n","stopwords = set(stopwords.words('english'))\n","\n","text = re.sub(r'[^\\w\\s]', '', df['text'][0])\n","text = text.lower()\n","\n","text_tokens = text.split()\n","text_tokens\n","text_list=[]\n","for word in text_tokens:\n","    if word not in stopwords and word not in string.punctuation:\n","        text_list.append(word)\n","text_list_stem = []\n","for word in text_list:\n","    text_list_stem.append(stemmer.stem(word))\n","print(' '.join(text_list_stem))"]},{"cell_type":"code","execution_count":267,"metadata":{"id":"yhU1BvAHdnLe"},"outputs":[],"source":["from nltk import stem\n","from nltk.corpus import stopwords\n","import re\n","import string  \n","\n","stemmer = stem.SnowballStemmer('english')\n","stopwords = set(stopwords.words('english'))\n","\n","def preprocess(text):\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    text = text.lower()\n","\n","    text_tokens = text.split()\n","    text_list=[]\n","    for word in text_tokens:\n","        if word not in stopwords and word not in string.punctuation:\n","            text_list.append(word)\n","    text_list_stem = []\n","    for word in text_list:\n","        text_list_stem.append(stemmer.stem(word))\n","    return ' '.join(text_list_stem)\n"]},{"cell_type":"markdown","metadata":{"id":"QM-Lrt6ddnLe"},"source":["Проверка, что функция работает верно"]},{"cell_type":"code","execution_count":268,"metadata":{"id":"RSuPqUb2dnLe"},"outputs":[],"source":["assert preprocess(\"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\") == \"im gonna home soon dont want talk stuff anymor tonight k ive cri enough today\"\n","assert preprocess(\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\") == \"go jurong point crazi avail bugi n great world la e buffet cine got amor wat\""]},{"cell_type":"markdown","metadata":{"id":"84H8mOmpdnLe"},"source":["Применяем получившуюся функцию к текстам:"]},{"cell_type":"code","execution_count":269,"metadata":{"id":"NtM4626ednLe"},"outputs":[],"source":["df['text'] = df['text'].apply(preprocess)"]},{"cell_type":"code","execution_count":270,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>go jurong point crazi avail bugi n great world...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>ok lar joke wif u oni</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>free entri 2 wkli comp win fa cup final tkts 2...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>u dun say earli hor u c alreadi say</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>nah dont think goe usf live around though</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5567</th>\n","      <td>1</td>\n","      <td>2nd time tri 2 contact u u å750 pound prize 2 ...</td>\n","    </tr>\n","    <tr>\n","      <th>5568</th>\n","      <td>0</td>\n","      <td>ì_ b go esplanad fr home</td>\n","    </tr>\n","    <tr>\n","      <th>5569</th>\n","      <td>0</td>\n","      <td>piti mood soani suggest</td>\n","    </tr>\n","    <tr>\n","      <th>5570</th>\n","      <td>0</td>\n","      <td>guy bitch act like id interest buy someth els ...</td>\n","    </tr>\n","    <tr>\n","      <th>5571</th>\n","      <td>0</td>\n","      <td>rofl true name</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5169 rows × 2 columns</p>\n","</div>"],"text/plain":["      label                                               text\n","0         0  go jurong point crazi avail bugi n great world...\n","1         0                              ok lar joke wif u oni\n","2         1  free entri 2 wkli comp win fa cup final tkts 2...\n","3         0                u dun say earli hor u c alreadi say\n","4         0          nah dont think goe usf live around though\n","...     ...                                                ...\n","5567      1  2nd time tri 2 contact u u å750 pound prize 2 ...\n","5568      0                           ì_ b go esplanad fr home\n","5569      0                            piti mood soani suggest\n","5570      0  guy bitch act like id interest buy someth els ...\n","5571      0                                     rofl true name\n","\n","[5169 rows x 2 columns]"]},"execution_count":270,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{"id":"gRyqtqUtdnLe"},"source":["### Разделение данных на обучающую и тестовую выборки (Задание 2)"]},{"cell_type":"code","execution_count":271,"metadata":{"id":"nt7Z5NCMdnLe"},"outputs":[],"source":["y = df['label']\n","X = df['text']"]},{"cell_type":"code","execution_count":272,"metadata":{},"outputs":[{"data":{"text/plain":["0       0\n","1       0\n","2       1\n","3       0\n","4       0\n","       ..\n","5567    1\n","5568    0\n","5569    0\n","5570    0\n","5571    0\n","Name: label, Length: 5169, dtype: int64"]},"execution_count":272,"metadata":{},"output_type":"execute_result"}],"source":["y"]},{"cell_type":"markdown","metadata":{"id":"6r4PJBctdnLe"},"source":["Теперь нужно разделить данные на тестовую (test) и обучающую (train) выборку. В библиотеке scikit-learn для этого есть готовые инструменты."]},{"cell_type":"code","execution_count":273,"metadata":{"id":"r1c9ARWIdnLe"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)"]},{"cell_type":"markdown","metadata":{"id":"KOV7Ub4ldnLe"},"source":["### Обучение классификатора (Задание 3)"]},{"cell_type":"markdown","metadata":{"id":"enAzNefqdnLe"},"source":["Переходим к обучению классификатора.\n","\n","Сначала извлекаем признаки из текстов. Рекомендуем попробовать разные способы и посмотреть, как это влияет на результат (подробнее о различных способах представления текстов можно прочитать по ссылке https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction).\n","\n","Затем обучаем классификатор. Мы используем SVM, но можно поэкспериментировать с различными алгоритмами."]},{"cell_type":"code","execution_count":274,"metadata":{"id":"QtfcmJ7NdnLe"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","\n","# извлекаем признаки из текстов\n","vectorizer = TfidfVectorizer(decode_error='ignore')\n","X_train = vectorizer.fit_transform(X_train)\n","X_test = vectorizer.transform(X_test)"]},{"cell_type":"code","execution_count":275,"metadata":{"id":"PIQQo8j3dnLe"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/muzafarov/anaconda3/envs/ML_OE/lib/python3.9/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n","  warnings.warn(\n"]}],"source":["from sklearn.svm import LinearSVC\n","from sklearn.metrics import classification_report\n","\n","#обучаем подель SVM\n","\n","model = LinearSVC(random_state = 41, C = 1.1)\n","model.fit(X_train, y_train)\n","predictions = model.predict(X_test)"]},{"cell_type":"markdown","metadata":{"id":"sn9kvQaZdnLe"},"source":["Для самопроверки. Если вы верно дополнили функцию ```preprocess```, то должны получиться следующие результаты оценки модели."]},{"cell_type":"code","execution_count":276,"metadata":{"id":"zGxDEYnjdnLe","outputId":"104a68f1-cf8a-421e-cc3f-2b63b99c2520"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0      0.977     0.994     0.986       898\n","           1      0.958     0.846     0.898       136\n","\n","    accuracy                          0.975      1034\n","   macro avg      0.968     0.920     0.942      1034\n","weighted avg      0.975     0.975     0.974      1034\n","\n"]}],"source":["print(classification_report(y_test, predictions, digits=3))"]},{"cell_type":"markdown","metadata":{"id":"1nffLu6UdnLf"},"source":["Выполним предсказание для конкретного текста"]},{"cell_type":"code","execution_count":277,"metadata":{"id":"prWswDzudnLf"},"outputs":[],"source":["txt = \"Take your prize, more than 100 computers, smartphones and TVs are supposed to be played in a free quiz. Call by phone 8 800 243 456\"\n","txt = preprocess(txt)\n","txt = vectorizer.transform([txt])"]},{"cell_type":"code","execution_count":278,"metadata":{"id":"brfpnzR7dnLf","outputId":"5220b6fe-a3a6-45f4-e726-b3f813ac7751"},"outputs":[{"data":{"text/plain":["array([1])"]},"execution_count":278,"metadata":{},"output_type":"execute_result"}],"source":["model.predict(txt)"]},{"cell_type":"markdown","metadata":{"id":"aVfQFiwGdnLf"},"source":["Сообщение помечено как спам."]}],"metadata":{"colab":{"collapsed_sections":[],"name":"3_Students.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
