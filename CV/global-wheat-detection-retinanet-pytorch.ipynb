{"cells":[{"cell_type":"markdown","metadata":{},"source":["# RetinaNet in PyTorch - Global Wheat Detection ðŸŒ¾\n","\n","In this notebook, I will show how to train RetinaNet for object detection using PyTorch. You can find more details [here](https://arxiv.org/pdf/1708.02002.pdf).  \n","  \n","I am using [this](https://github.com/yhenon/pytorch-retinanet) implementation of RetinaNet in PyTorch by [yhenon](https://github.com/yhenon).\n"]},{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-output":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'pytorch-retinanet'...\n","remote: Enumerating objects: 232, done.\u001b[K\n","remote: Total 232 (delta 0), reused 0 (delta 0), pack-reused 232\u001b[K\n","Receiving objects: 100% (232/232), 1.02 MiB | 4.14 MiB/s, done.\n","Resolving deltas: 100% (119/119), done.\n"]}],"source":["### Cloning Github Repository \n","!git clone https://github.com/yhenon/pytorch-retinanet.git"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cp: /kaggle/working/pytorch-retinanet/retinanet: No such file or directory\n"]}],"source":["### Copying RetinaNet Folder to root dir so we can import it easily\n","!cp -r /kaggle/working/pytorch-retinanet/retinanet ./"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"outputs":[],"source":["!pip install pycocotools"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import re\n","import cv2\n","import time\n","import numpy as np\n","import pandas as pd\n","\n","\n","import torch\n","import torch.optim as optim\n","import torchvision.transforms as T\n","from torchvision.utils import make_grid \n","from torch.utils.data import DataLoader, Dataset\n","\n","from retinanet import model\n","from retinanet.dataloader import collater, Resizer, Augmenter, Normalizer, UnNormalizer\n","\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","\n","DIR = \"../input/global-wheat-detection/\"\n","DIR_TRAIN = DIR + \"train\"\n","DIR_TEST = DIR + \"test\""]},{"cell_type":"markdown","metadata":{},"source":["# Exploring Dataset ðŸ“Š"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### Loading Dataset\n","df = pd.read_csv(DIR + \"train.csv\")\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["Converting bbox list from original df to some appropriate form"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["### Converting bbox list in appropriate form\n","\n","df['x'] = -1\n","df['y'] = -1\n","df['w'] = -1\n","df['h'] = -1\n","\n","def expand_bbox(x):\n","    r = np.array(re.findall(\"([0-9]+[.]?[0-9]*)\", x))\n","    if len(r) == 0:\n","        r = [-1, -1, -1, -1]\n","    return r\n","\n","df[['x', 'y', 'w', 'h']] = np.stack(df['bbox'].apply(lambda x: expand_bbox(x)))\n","df.drop(columns=['bbox'], inplace=True)\n","df['x'] = df['x'].astype(np.float)\n","df['y'] = df['y'].astype(np.float)\n","df['w'] = df['w'].astype(np.float)\n","df['h'] = df['h'].astype(np.float)\n","\n","df.head()\n"]},{"cell_type":"markdown","metadata":{},"source":["Null Values, Unique Images, etc."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["### Null Values, Unique Images, etc.\n","\n","unq_values = df[\"image_id\"].unique()\n","print(\"Total Records: \", len(df))\n","print(\"Unique Images: \",len(unq_values))\n","\n","null_values = df.isnull().sum(axis = 0)\n","print(\"\\n> Null Values in each column <\")\n","print(null_values)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"trusted":true},"outputs":[],"source":["### Data Sources\n","\n","sources = df[\"source\"].unique()\n","print(\"Total Sources: \",len(sources))\n","print(\"\\n> Sources <\\n\",sources)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### Visualizing Source Distribution\n","\n","plt.figure(figsize=(14,8))\n","plt.title('Source Distribution', fontsize= 20)\n","sns.countplot(x = \"source\", data = df)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### Splitting Train Dataset into train - val (80:20)\n","\n","images = df['image_id'].unique()\n","valid_imgs = images[-674:]\n","train_imgs = images[:-674]\n","\n","valid_df = df[df['image_id'].isin(valid_imgs)]\n","train_df = df[df['image_id'].isin(train_imgs)]\n"]},{"cell_type":"markdown","metadata":{},"source":["# Visualize Random Images with BBox ðŸ•µï¸â€"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["### Function to plot image\n","\n","def plot_img(image_name):\n","    \n","    fig, ax = plt.subplots(1, 2, figsize = (10, 10))\n","    ax = ax.flatten()\n","    \n","    records = df[df['image_id'] == image_name]\n","    img_path = os.path.join(DIR_TRAIN, image_name + \".jpg\")\n","    \n","    image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n","    image /= 255.0\n","    image2 = image\n","    \n","    ax[0].set_title('Original Image')\n","    ax[0].imshow(image)\n","    \n","    for idx, row in records.iterrows():\n","        box = row[['x', 'y', 'w', 'h']].values\n","        xmin = box[0]\n","        ymin = box[1]\n","        width = box[2]\n","        height = box[3]\n","        \n","        cv2.rectangle(image2, (int(xmin),int(ymin)), (int(xmin + width),int(ymin + height)), (255,0,0), 3)\n","    \n","    ax[1].set_title('Image with Bondary Box')\n","    ax[1].imshow(image2)\n","\n","    plt.show()\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### Pass any image id as parameter\n","\n","plot_img(\"0126b7d11\")\n","plot_img(\"00333207f\")"]},{"cell_type":"markdown","metadata":{"trusted":true},"source":["# Preparing Dataset for Training ðŸ“‚"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### Creating targets for model using Dataset Class\n","\n","class GWD(Dataset):\n","\n","    def __init__(self, dataframe, image_dir, mode = \"train\", transforms = None):\n","        \n","        super().__init__()\n","        self.image_ids = dataframe['image_id'].unique()\n","        self.df = dataframe\n","        self.image_dir = image_dir\n","        self.mode = mode\n","        self.transforms = transforms\n","\n","    def __getitem__(self, index: int):\n","\n","        # Retriving image id and records from df\n","        image_id = self.image_ids[index]\n","        records = self.df[self.df['image_id'] == image_id]\n","\n","        # Loading Image\n","        image = cv2.imread(f'{self.image_dir}/{image_id}.jpg', cv2.IMREAD_COLOR)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n","        image /= 255.0\n","\n","        # If mode is set to train, then only we create targets\n","        if self.mode == \"train\" or self.mode == \"valid\":\n","\n","            # Converting xmin, ymin, w, h to x1, y1, x2, y2\n","            boxes = np.zeros((records.shape[0], 5))\n","            boxes[:, 0:4] = records[['x', 'y', 'w', 'h']].values\n","            boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n","            boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n","            boxes[:, 4] = 1 # This is for label, as we have only 1 class, it is always 1\n","            \n","            # Applying Transforms\n","            sample = {'img': image, 'annot': boxes}\n","                \n","            if self.transforms:\n","                sample = self.transforms(sample)\n","\n","            return sample\n","        \n","        elif self.mode == \"test\":\n","            \n","            # We just need to apply transoforms and return image\n","            if self.transforms:\n","                \n","                sample = {'img' : image}\n","                sample = self.transforms(sample)\n","                \n","            return sample\n","        \n","\n","    def __len__(self) -> int:\n","        return self.image_ids.shape[0]\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### Preparing Datasets and Dataloaders for Training \n","\n","# Dataset Object\n","train_dataset = GWD(train_df, DIR_TRAIN, mode = \"train\", transforms = T.Compose([Augmenter(), Normalizer(), Resizer()]))\n","valid_dataset = GWD(valid_df, DIR_TRAIN, mode = \"valid\", transforms = T.Compose([Normalizer(), Resizer()]))\n","\n","# DataLoaders\n","train_data_loader = DataLoader(\n","    train_dataset,\n","    batch_size = 8,\n","    shuffle = True,\n","    num_workers = 4,\n","    collate_fn = collater\n",")\n","\n","valid_data_loader = DataLoader(\n","    valid_dataset,\n","    batch_size = 8,\n","    shuffle = True,\n","    num_workers = 4,\n","    collate_fn = collater\n",")\n","\n","\n","test_data_loader = DataLoader(\n","    valid_dataset,\n","    batch_size = 1,\n","    shuffle = True,\n","    num_workers = 4,\n","    collate_fn = collater\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Create Model - RetinaNet ðŸ”¨"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### Utilize GPU if available\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### I am using Pre-trained Resnet50 as backbone\n","\n","retinanet = model.resnet50(num_classes = 2, pretrained = True)\n","\n","# Loading Pre-trained model - if you load pre-trained model, comment above line.\n","#retinanet = torch.load(\"path_to_.pt_file\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### Preparing model for training\n","\n","# Defininig Optimizer\n","optimizer = torch.optim.Adam(retinanet.parameters(), lr = 0.0001)\n","\n","# Learning Rate Scheduler\n","#lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma=0.5)\n","\n","retinanet.to(device)\n","\n","#No of epochs\n","epochs = 15\n"]},{"cell_type":"markdown","metadata":{},"source":["# Now comes everbody's favorite part ðŸ˜‹, let's train it!\n","I have defined functions to just improve the readability of the code, model and other parameters are defined outside."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### One Epoch - Train\n","\n","def train_one_epoch(epoch_num, train_data_loader):\n","    \n","    print(\"Epoch - {} Started\".format(epoch_num))\n","    st = time.time()\n","    \n","    retinanet.train()\n","    \n","    epoch_loss = []\n","\n","    for iter_num, data in enumerate(train_data_loader):\n","                \n","        # Reseting gradients after each iter\n","        optimizer.zero_grad()\n","            \n","        # Forward\n","        classification_loss, regression_loss = retinanet([data['img'].cuda().float(), data['annot'].cuda().float()])\n","                \n","        # Calculating Loss\n","        classification_loss = classification_loss.mean()\n","        regression_loss = regression_loss.mean()\n","\n","        loss = classification_loss + regression_loss\n","\n","        if bool(loss == 0):\n","            continue\n","                \n","        # Calculating Gradients\n","        loss.backward()\n","\n","        # Gradient Clipping\n","        torch.nn.utils.clip_grad_norm_(retinanet.parameters(), 0.1)\n","                \n","        # Updating Weights\n","        optimizer.step()\n","\n","        #Epoch Loss\n","        epoch_loss.append(float(loss))\n","\n","            \n","        print(\n","            'Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n","                epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(epoch_loss)))\n","\n","        del classification_loss\n","        del regression_loss\n","        \n","    # Update the learning rate\n","    #if lr_scheduler is not None:\n","        #lr_scheduler.step()\n","        \n","    et = time.time()\n","    print(\"\\n Total Time - {}\\n\".format(int(et - st)))\n","    \n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### One Epoch - Valid\n","\n","def valid_one_epoch(epoch_num, valid_data_loader):\n","    \n","    print(\"Epoch - {} Started\".format(epoch_num))\n","    st = time.time()\n","    \n","    epoch_loss = []\n","\n","    for iter_num, data in enumerate(valid_data_loader):\n","                \n","        with torch.no_grad():\n","            \n","            # Forward\n","            classification_loss, regression_loss = retinanet([data['img'].cuda().float(), data['annot'].cuda().float()])\n","\n","            # Calculating Loss\n","            classification_loss = classification_loss.mean()\n","            regression_loss = regression_loss.mean()\n","            loss = classification_loss + regression_loss\n","\n","            #Epoch Loss\n","            epoch_loss.append(float(loss))\n","\n","            print(\n","                'Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n","                    epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(epoch_loss)))\n","\n","            del classification_loss\n","            del regression_loss\n","        \n","    et = time.time()\n","    print(\"\\n Total Time - {}\\n\".format(int(et - st)))\n","    \n","    # Save Model after each epoch\n","    torch.save(retinanet, \"retinanet_gwd.pt\")\n","    \n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["### Training Loop\n","for epoch in range(epochs):\n","    \n","    # Call train function\n","    train_one_epoch(epoch, train_data_loader)\n","    \n","    # Call valid function\n","    valid_one_epoch(epoch, valid_data_loader)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### Sample Results\n","retinanet.eval()\n","unnormalize = UnNormalizer()\n","\n","for iter_num, data in enumerate(test_data_loader):\n","    \n","    # Getting Predictions\n","    scores, classification, transformed_anchors = retinanet(data['img'].cuda().float())\n","    \n","    idxs = np.where(scores.cpu()>0.5)\n","    img = np.array(255 * unnormalize(data['img'][0, :, :, :])).copy()\n","    \n","    img[img<0] = 0\n","    img[img>255] = 255\n","\n","    img = np.transpose(img, (1, 2, 0))\n","\n","    img = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)\n","    \n","    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n","    \n","    for j in range(idxs[0].shape[0]):\n","        bbox = transformed_anchors[idxs[0][j], :]\n","        x1 = int(bbox[0])\n","        y1 = int(bbox[1])\n","        x2 = int(bbox[2])\n","        y2 = int(bbox[3])\n","\n","        cv2.rectangle(img, (x1, y1), (x2, y2), color = (0, 0, 255), thickness = 2)\n","        \n","    ax.imshow(img)\n","    \n","    break\n","    "]},{"cell_type":"markdown","metadata":{},"source":["Hope you liked it ðŸ˜œ, comment below your suggestions / feedback. I will upload another notebook for inference soon."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":4}
