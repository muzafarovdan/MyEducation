{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /private/var/folders/yj/nhkf3nv505d5kh0dsk42f3ym0000gn/T/pip-req-build-fhoths50\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /private/var/folders/yj/nhkf3nv505d5kh0dsk42f3ym0000gn/T/pip-req-build-fhoths50\n",
      "  Resolved https://github.com/openai/whisper.git to commit 8bc8860694949db53c42ba47ddc23786c2e02a8b\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numba (from openai-whisper==20231117)\n",
      "  Downloading numba-0.58.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting numpy (from openai-whisper==20231117)\n",
      "  Downloading numpy-1.26.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch (from openai-whisper==20231117)\n",
      "  Downloading torch-2.1.1-cp310-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Collecting tqdm (from openai-whisper==20231117)\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting more-itertools (from openai-whisper==20231117)\n",
      "  Using cached more_itertools-10.1.0-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting tiktoken (from openai-whisper==20231117)\n",
      "  Downloading tiktoken-0.5.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba->openai-whisper==20231117)\n",
      "  Downloading llvmlite-0.41.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->openai-whisper==20231117)\n",
      "  Using cached regex-2023.10.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
      "Collecting filelock (from torch->openai-whisper==20231117)\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (4.9.0)\n",
      "Collecting sympy (from torch->openai-whisper==20231117)\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx (from torch->openai-whisper==20231117)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch->openai-whisper==20231117)\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec (from torch->openai-whisper==20231117)\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch->openai-whisper==20231117)\n",
      "  Downloading MarkupSafe-2.1.3-cp310-cp310-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch->openai-whisper==20231117)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached more_itertools-10.1.0-py3-none-any.whl (55 kB)\n",
      "Downloading numba-0.58.1-cp310-cp310-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading numpy-1.26.2-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.5.2-cp310-cp310-macosx_11_0_arm64.whl (953 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.1-cp310-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Downloading llvmlite-0.41.1-cp310-cp310-macosx_11_0_arm64.whl (28.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached regex-2023.10.3-cp310-cp310-macosx_11_0_arm64.whl (291 kB)\n",
      "Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Downloading MarkupSafe-2.1.3-cp310-cp310-macosx_10_9_universal2.whl (17 kB)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801404 sha256=2f2aaa7df331c09b707127af33c122bf10a4654d301b09712e756251e1d0b50d\n",
      "  Stored in directory: /private/var/folders/yj/nhkf3nv505d5kh0dsk42f3ym0000gn/T/pip-ephem-wheel-cache-pbqyjsam/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: mpmath, tqdm, sympy, regex, numpy, networkx, more-itertools, MarkupSafe, llvmlite, fsspec, filelock, tiktoken, numba, jinja2, torch, openai-whisper\n",
      "Successfully installed MarkupSafe-2.1.3 filelock-3.13.1 fsspec-2023.12.2 jinja2-3.1.2 llvmlite-0.41.1 more-itertools-10.1.0 mpmath-1.3.0 networkx-3.2.1 numba-0.58.1 numpy-1.26.2 openai-whisper-20231117 regex-2023.10.3 sympy-1.12 tiktoken-0.5.2 torch-2.1.1 tqdm-4.66.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: fkhdxka3c8E\n",
      "[youtube] fkhdxka3c8E: Downloading webpage\n",
      "[youtube] fkhdxka3c8E: Downloading ios player API JSON\n",
      "[youtube] fkhdxka3c8E: Downloading android player API JSON\n",
      "[youtube] fkhdxka3c8E: Downloading m3u8 information\n",
      "[info] fkhdxka3c8E: Downloading 1 format(s): 251\n",
      "[download] Destination: random_video.webm\n",
      "\u001b[K[download] 100% of    2.87MiB in \u001b[1;37m00:00:00\u001b[0m at \u001b[0;32m20.26MiB/s\u001b[0m;33m00:00\u001b[0m\n",
      "[ExtractAudio] Destination: random_video.mp3\n",
      "Deleting original file random_video.webm (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "!yt-dlp -x --audio-format mp3 -o random_video.mp3 -- fkhdxka3c8E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "[00:00.000 --> 00:04.400]  Всем привет! Меня зовут Мария, я школьный учитель и делюсь своим опытом.\n",
      "[00:04.400 --> 00:09.000]  В этом видео мы поговорим о построении онлайн уроков, онлайн занятий.\n",
      "[00:09.000 --> 00:14.000]  Я делюсь лишь своим опытом, своим видением, как это должно происходить.\n",
      "[00:14.000 --> 00:18.800]  И если было полезно, обязательно поставьте реакцию на данный ролик.\n",
      "[00:20.000 --> 00:27.200]  Если б офлайн занятий урок держится на живой коммуникации, то онлайн занятия живет за счет практической работы.\n",
      "[00:27.200 --> 00:31.200]  Практическим образом мы повторяем материал, изучаем и закрепляем его.\n",
      "[00:31.200 --> 00:36.200]  Изучение теории необходимо максимально отодвигать на неурочное время.\n",
      "[00:36.200 --> 00:42.200]  Здесь вам помогут электронные образовательные ресурсы, инфографика, статьи, видеоконтент.\n",
      "[00:42.200 --> 00:46.200]  Причем все это можно находить в свободном доступе или создавать самостоятельно.\n",
      "[00:46.200 --> 00:52.200]  Например, в своем телеграм-канале я уже упоминала о программе Screenshotter для записи видео.\n",
      "[00:52.200 --> 00:58.200]  Также, чтобы записать онлайн объяснение, возможно, вам понадобится презентация или программа для записи заметок.\n",
      "[00:58.200 --> 01:00.200]  А может быть и то, и другое.\n",
      "[01:00.200 --> 01:04.200]  Что касается практической работы с учениками во время онлайн занятия,\n",
      "[01:04.200 --> 01:09.200]  здесь вы ограничены лишь своей осведомленностью о тех или иных способах сетевого взаимодействия.\n",
      "[01:09.200 --> 01:14.200]  Вы можете организовать групповую работу или игру в бесконечной онлайн-доске,\n",
      "[01:14.200 --> 01:20.200]  использовать элементы игровых технологий на уроке или гимнифицировать весь процесс обучения.\n",
      "[01:20.200 --> 01:24.200]  Например, можно воспользоваться сервисами миллионенапции или вип-фити.\n",
      "[01:24.200 --> 01:28.200]  Построить коллективное взаимодействие в гугл-сервисах ему подобных.\n",
      "[01:28.200 --> 01:32.200]  Общая работа с документами, таблецами, презентацией, гугл-формы.\n",
      "[01:32.200 --> 01:37.200]  При всем при этом важно сохранить весь учебный контент в одном конкретном месте,\n",
      "[01:37.200 --> 01:42.200]  таким образом, чтобы каждый обучающийся мог в любое время дня и ночи иметь доступ к нему.\n",
      "[01:42.200 --> 01:46.200]  Здесь нам поможет общий доступ в папке на вашем облаке\n",
      "[01:46.200 --> 01:53.200]  или, возможно, даже телеграм-канал или группа во Вконтакте, там, где вам удобнее работать.\n",
      "[01:53.200 --> 01:58.200]  Желательно иметь общий чат для поддержки связи с учениками во мне урочное время.\n",
      "[01:58.200 --> 02:04.200]  А для построения взаимодействия вам также могут помочь программы по типам Microsoft Teams.\n",
      "[02:04.200 --> 02:08.200]  Рекомендую изучить, потому что в них собрано все самое лучшее,\n",
      "[02:08.200 --> 02:11.200]  что необходимо для организации такого обучения.\n",
      "[02:11.200 --> 02:15.200]  А мимо практической работы необходимо тщательно продумать систему оценивания.\n",
      "[02:15.200 --> 02:19.200]  Каким образом и где будет проходить контроль знаний ваших подопечных,\n",
      "[02:19.200 --> 02:24.200]  каким образом вы будете сообщать им результаты и не забываем об этики.\n",
      "[02:24.200 --> 02:27.200]  Никто не должен видеть чужую работу или результат.\n",
      "[02:27.200 --> 02:31.200]  Ребята сами поделятся друг с другом, если это будет необходимо.\n",
      "[02:31.200 --> 02:34.200]  Проверку работ можно проводить в ранее упомянутых сервисах,\n",
      "[02:34.200 --> 02:37.200]  те же гугл-формы с выводом статистики.\n",
      "[02:37.200 --> 02:41.200]  А также, если ребятам предстоит большая письменная работа,\n",
      "[02:41.200 --> 02:45.200]  вы можете воспользоваться, например, сервисом Cloud Text.\n",
      "[02:45.200 --> 02:50.200]  Это был мой опыт и мое видение организации онлайн занятий.\n",
      "[02:50.200 --> 02:55.200]  Если вы имеете такой опыт, не скупитесь поделиться им в комментариях.\n",
      "[02:55.200 --> 02:58.200]  Возможно, кому-то он сейчас сильно поможет.\n",
      "[02:58.200 --> 03:01.200]  Большое спасибо за просмотр, за поддержку канала.\n",
      "[03:01.200 --> 03:04.200]  Увидимся с вами еще все предложения и замечания.\n",
      "[03:04.200 --> 03:06.200]  Пишите здесь в комментариях.\n",
      "[03:06.200 --> 03:07.200]  Всем пока!\n"
     ]
    }
   ],
   "source": [
    "!whisper --language ru --model small -o ./result -- random_video.mp3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EdControl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
