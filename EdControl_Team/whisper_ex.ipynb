{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /private/var/folders/yj/nhkf3nv505d5kh0dsk42f3ym0000gn/T/pip-req-build-rrv6r0li\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /private/var/folders/yj/nhkf3nv505d5kh0dsk42f3ym0000gn/T/pip-req-build-rrv6r0li\n",
      "  Resolved https://github.com/openai/whisper.git to commit 8bc8860694949db53c42ba47ddc23786c2e02a8b\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from openai-whisper==20231117) (0.58.1)\n",
      "Requirement already satisfied: numpy in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from openai-whisper==20231117) (1.26.0)\n",
      "Requirement already satisfied: torch in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from openai-whisper==20231117) (2.1.1)\n",
      "Requirement already satisfied: tqdm in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from openai-whisper==20231117) (4.66.1)\n",
      "Requirement already satisfied: more-itertools in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from openai-whisper==20231117) (10.1.0)\n",
      "Requirement already satisfied: tiktoken in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from openai-whisper==20231117) (0.5.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
      "Requirement already satisfied: filelock in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (2023.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: tRsNLrpk3D0\n",
      "[youtube] tRsNLrpk3D0: Downloading webpage\n",
      "[youtube] tRsNLrpk3D0: Downloading ios player API JSON\n",
      "[youtube] tRsNLrpk3D0: Downloading android player API JSON\n",
      "[youtube] tRsNLrpk3D0: Downloading m3u8 information\n",
      "[info] tRsNLrpk3D0: Downloading 1 format(s): 258\n",
      "[download] Destination: dialog.m4a\n",
      "\u001b[K[download] 100% of    8.01MiB in \u001b[1;37m00:00:00\u001b[0m at \u001b[0;32m9.38MiB/s\u001b[0m0;33m00:00\u001b[0m\n",
      "[FixupM4a] Correcting container of \"dialog.m4a\"\n",
      "[ExtractAudio] Destination: dialog.mp3\n",
      "Deleting original file dialog.m4a (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "!yt-dlp -x --audio-format mp3 -o dialog.mp3 -- tRsNLrpk3D0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/bin/whisper\", line 8, in <module>\n",
      "    sys.exit(cli())\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/transcribe.py\", line 478, in cli\n",
      "    result = transcribe(model, audio_path, temperature=temperature, **args)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/transcribe.py\", line 240, in transcribe\n",
      "    result: DecodingResult = decode_with_fallback(mel_segment)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/transcribe.py\", line 170, in decode_with_fallback\n",
      "    decode_result = model.decode(segment, options)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/decoding.py\", line 824, in decode\n",
      "    result = DecodingTask(model, options).run(mel)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/decoding.py\", line 737, in run\n",
      "    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/decoding.py\", line 687, in _main_loop\n",
      "    logits = self.inference.logits(tokens, audio_features)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/decoding.py\", line 163, in logits\n",
      "    return self.model.decoder(tokens, audio_features, kv_cache=self.kv_cache)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/model.py\", line 211, in forward\n",
      "    x = block(x, xa, mask=self.mask, kv_cache=kv_cache)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/model.py\", line 138, in forward\n",
      "    x = x + self.cross_attn(self.cross_attn_ln(x), xa, kv_cache=kv_cache)[0]\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/model.py\", line 90, in forward\n",
      "    wv, qk = self.qkv_attention(q, k, v, mask)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/model.py\", line 103, in qkv_attention\n",
      "    if mask is not None:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!whisper --language ru --model small -o ./result -- random_video.mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f803d1649f641258021d27afd84bbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/469 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchvision is not available - cannot save figures\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfebe00dbd04bde9fac5371ce171c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/5.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc046ec8e75432493b40bdb7bfa8fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76032908a4364c54aa2b0a9f518dc873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/26.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf95a420d08470d96fe91f9e7e8f4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/221 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# instantiate the pipeline\n",
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "  \"pyannote/speaker-diarization-3.1\",\n",
    "  use_auth_token=\"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\")\n",
    "\n",
    "# run the pipeline on an audio file\n",
    "diarization = pipeline(\"audio.mp3\", num_speakers=2)\n",
    "\n",
    "# dump the diarization output to disk using RTTM format\n",
    "with open(\"audio.mp3\", \"w\") as rttm:\n",
    "    diarization.write_rttm(rttm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EdControl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
