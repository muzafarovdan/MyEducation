{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /private/var/folders/yj/nhkf3nv505d5kh0dsk42f3ym0000gn/T/pip-req-build-r8bayxoc\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /private/var/folders/yj/nhkf3nv505d5kh0dsk42f3ym0000gn/T/pip-req-build-r8bayxoc\n",
      "  Resolved https://github.com/openai/whisper.git to commit 8bc8860694949db53c42ba47ddc23786c2e02a8b\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from openai-whisper==20231117) (0.58.1)\n",
      "Requirement already satisfied: numpy in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from openai-whisper==20231117) (1.26.0)\n",
      "Requirement already satisfied: torch in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from openai-whisper==20231117) (2.1.1)\n",
      "Requirement already satisfied: tqdm in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from openai-whisper==20231117) (4.66.1)\n",
      "Requirement already satisfied: more-itertools in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from openai-whisper==20231117) (10.1.0)\n",
      "Requirement already satisfied: tiktoken in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from openai-whisper==20231117) (0.5.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
      "Requirement already satisfied: filelock in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (2023.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: NzYqQ4gRmyM\n",
      "[youtube] NzYqQ4gRmyM: Downloading webpage\n",
      "[youtube] NzYqQ4gRmyM: Downloading ios player API JSON\n",
      "[youtube] NzYqQ4gRmyM: Downloading android player API JSON\n",
      "[youtube] NzYqQ4gRmyM: Downloading m3u8 information\n",
      "[youtube] NzYqQ4gRmyM: Downloading MPD manifest\n",
      "[info] NzYqQ4gRmyM: Downloading 1 format(s): 251\n",
      "[download] dialog.mp3 has already been downloaded\n",
      "[ExtractAudio] Not converting audio dialog.mp3; file is already in target format mp3\n"
     ]
    }
   ],
   "source": [
    "!yt-dlp -x --audio-format mp3 -o dialog.mp3 -- NzYqQ4gRmyM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/bin/whisper\", line 8, in <module>\n",
      "    sys.exit(cli())\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/transcribe.py\", line 478, in cli\n",
      "    result = transcribe(model, audio_path, temperature=temperature, **args)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/transcribe.py\", line 240, in transcribe\n",
      "    result: DecodingResult = decode_with_fallback(mel_segment)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/transcribe.py\", line 170, in decode_with_fallback\n",
      "    decode_result = model.decode(segment, options)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/decoding.py\", line 824, in decode\n",
      "    result = DecodingTask(model, options).run(mel)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/decoding.py\", line 737, in run\n",
      "    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/decoding.py\", line 687, in _main_loop\n",
      "    logits = self.inference.logits(tokens, audio_features)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/decoding.py\", line 163, in logits\n",
      "    return self.model.decoder(tokens, audio_features, kv_cache=self.kv_cache)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/model.py\", line 211, in forward\n",
      "    x = block(x, xa, mask=self.mask, kv_cache=kv_cache)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/model.py\", line 138, in forward\n",
      "    x = x + self.cross_attn(self.cross_attn_ln(x), xa, kv_cache=kv_cache)[0]\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/model.py\", line 90, in forward\n",
      "    wv, qk = self.qkv_attention(q, k, v, mask)\n",
      "  File \"/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/whisper/model.py\", line 103, in qkv_attention\n",
      "    if mask is not None:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!whisper --language ru --model small -o ./result -- random_video.mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "/Users/muzafarov/anaconda3/envs/EdControl/lib/python3.10/site-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f803d1649f641258021d27afd84bbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/469 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchvision is not available - cannot save figures\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfebe00dbd04bde9fac5371ce171c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/5.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc046ec8e75432493b40bdb7bfa8fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76032908a4364c54aa2b0a9f518dc873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/26.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf95a420d08470d96fe91f9e7e8f4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml:   0%|          | 0.00/221 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# instantiate the pipeline\n",
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "  \"pyannote/speaker-diarization-3.1\",\n",
    "  use_auth_token=\"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\")\n",
    "\n",
    "# run the pipeline on an audio file\n",
    "diarization = pipeline(\"audio.mp3\", num_speakers=2)\n",
    "\n",
    "# dump the diarization output to disk using RTTM format\n",
    "with open(\"audio.mp3\", \"w\") as rttm:\n",
    "    diarization.write_rttm(rttm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=1.2s stop=2.2s speaker_SPEAKER_00\n",
      "start=3.8s stop=4.8s speaker_SPEAKER_01\n",
      "start=5.5s stop=6.5s speaker_SPEAKER_00\n",
      "start=7.4s stop=9.0s speaker_SPEAKER_01\n",
      "start=9.0s stop=9.3s speaker_SPEAKER_00\n",
      "start=10.8s stop=11.4s speaker_SPEAKER_00\n",
      "start=12.4s stop=13.2s speaker_SPEAKER_01\n",
      "start=14.2s stop=14.4s speaker_SPEAKER_01\n",
      "start=16.6s stop=17.1s speaker_SPEAKER_00\n",
      "start=18.0s stop=19.2s speaker_SPEAKER_00\n",
      "start=21.3s stop=22.0s speaker_SPEAKER_01\n",
      "start=25.9s stop=27.2s speaker_SPEAKER_00\n",
      "start=30.1s stop=31.2s speaker_SPEAKER_01\n",
      "start=32.7s stop=33.0s speaker_SPEAKER_01\n",
      "start=33.7s stop=34.2s speaker_SPEAKER_00\n",
      "start=35.9s stop=36.1s speaker_SPEAKER_00\n",
      "start=36.7s stop=36.8s speaker_SPEAKER_00\n",
      "start=37.0s stop=38.3s speaker_SPEAKER_00\n",
      "start=42.0s stop=43.1s speaker_SPEAKER_01\n",
      "start=44.1s stop=45.8s speaker_SPEAKER_00\n",
      "start=49.2s stop=50.0s speaker_SPEAKER_01\n",
      "start=53.1s stop=53.4s speaker_SPEAKER_00\n",
      "start=54.0s stop=56.8s speaker_SPEAKER_01\n",
      "start=57.5s stop=58.3s speaker_SPEAKER_00\n",
      "start=59.3s stop=59.8s speaker_SPEAKER_01\n",
      "start=60.0s stop=60.7s speaker_SPEAKER_00\n",
      "start=60.3s stop=61.3s speaker_SPEAKER_01\n",
      "start=62.5s stop=67.5s speaker_SPEAKER_01\n",
      "start=68.1s stop=68.5s speaker_SPEAKER_01\n",
      "start=69.4s stop=70.6s speaker_SPEAKER_00\n",
      "start=73.1s stop=74.6s speaker_SPEAKER_01\n",
      "start=75.8s stop=75.8s speaker_SPEAKER_02\n",
      "start=75.8s stop=76.0s speaker_SPEAKER_00\n",
      "start=76.0s stop=76.3s speaker_SPEAKER_02\n",
      "start=77.1s stop=77.5s speaker_SPEAKER_01\n",
      "start=80.4s stop=80.7s speaker_SPEAKER_02\n",
      "start=81.8s stop=82.0s speaker_SPEAKER_02\n",
      "start=82.0s stop=82.1s speaker_SPEAKER_02\n",
      "start=83.9s stop=85.6s speaker_SPEAKER_00\n",
      "start=87.2s stop=88.3s speaker_SPEAKER_00\n",
      "start=89.1s stop=90.2s speaker_SPEAKER_00\n",
      "start=90.2s stop=91.0s speaker_SPEAKER_00\n",
      "start=90.5s stop=94.3s speaker_SPEAKER_01\n",
      "start=94.6s stop=95.6s speaker_SPEAKER_00\n",
      "start=96.3s stop=101.8s speaker_SPEAKER_00\n",
      "start=103.0s stop=104.1s speaker_SPEAKER_01\n",
      "start=105.5s stop=105.5s speaker_SPEAKER_02\n",
      "start=105.5s stop=106.2s speaker_SPEAKER_00\n",
      "start=107.9s stop=109.1s speaker_SPEAKER_01\n",
      "start=110.7s stop=111.0s speaker_SPEAKER_00\n",
      "start=112.9s stop=113.0s speaker_SPEAKER_02\n",
      "start=116.4s stop=117.5s speaker_SPEAKER_00\n",
      "start=118.2s stop=118.5s speaker_SPEAKER_00\n",
      "start=119.6s stop=120.7s speaker_SPEAKER_00\n",
      "start=121.1s stop=122.0s speaker_SPEAKER_00\n",
      "start=122.0s stop=123.7s speaker_SPEAKER_00\n",
      "start=124.9s stop=125.5s speaker_SPEAKER_00\n",
      "start=125.8s stop=126.9s speaker_SPEAKER_00\n",
      "start=127.4s stop=127.6s speaker_SPEAKER_00\n",
      "start=128.5s stop=129.3s speaker_SPEAKER_00\n",
      "start=130.2s stop=132.3s speaker_SPEAKER_00\n",
      "start=134.3s stop=136.2s speaker_SPEAKER_01\n",
      "start=137.5s stop=137.9s speaker_SPEAKER_00\n",
      "start=141.2s stop=144.0s speaker_SPEAKER_00\n",
      "start=145.0s stop=145.7s speaker_SPEAKER_01\n",
      "start=146.3s stop=146.8s speaker_SPEAKER_01\n",
      "start=149.4s stop=149.8s speaker_SPEAKER_00\n",
      "start=149.8s stop=150.0s speaker_SPEAKER_02\n",
      "start=157.1s stop=160.8s speaker_SPEAKER_00\n",
      "start=161.2s stop=165.2s speaker_SPEAKER_00\n",
      "start=166.6s stop=167.0s speaker_SPEAKER_01\n",
      "start=168.0s stop=168.3s speaker_SPEAKER_00\n",
      "start=168.7s stop=171.3s speaker_SPEAKER_00\n",
      "start=170.2s stop=170.9s speaker_SPEAKER_01\n",
      "start=172.1s stop=173.1s speaker_SPEAKER_00\n",
      "start=173.9s stop=175.4s speaker_SPEAKER_00\n",
      "start=176.7s stop=177.2s speaker_SPEAKER_00\n",
      "start=178.2s stop=180.9s speaker_SPEAKER_00\n",
      "start=183.9s stop=184.2s speaker_SPEAKER_02\n",
      "start=184.7s stop=184.9s speaker_SPEAKER_00\n",
      "start=185.5s stop=185.5s speaker_SPEAKER_02\n",
      "start=185.5s stop=185.5s speaker_SPEAKER_00\n",
      "start=185.5s stop=185.9s speaker_SPEAKER_02\n",
      "start=188.7s stop=189.2s speaker_SPEAKER_02\n",
      "start=197.5s stop=198.0s speaker_SPEAKER_00\n",
      "start=199.0s stop=200.0s speaker_SPEAKER_00\n",
      "start=202.3s stop=202.8s speaker_SPEAKER_02\n",
      "start=204.3s stop=204.8s speaker_SPEAKER_00\n",
      "start=207.6s stop=211.4s speaker_SPEAKER_00\n",
      "start=212.5s stop=212.9s speaker_SPEAKER_00\n",
      "start=214.2s stop=216.1s speaker_SPEAKER_00\n",
      "start=216.9s stop=218.7s speaker_SPEAKER_00\n",
      "start=220.2s stop=221.2s speaker_SPEAKER_00\n",
      "start=221.6s stop=223.2s speaker_SPEAKER_00\n",
      "start=226.1s stop=226.3s speaker_SPEAKER_00\n",
      "start=228.8s stop=230.3s speaker_SPEAKER_00\n",
      "start=231.1s stop=232.5s speaker_SPEAKER_00\n",
      "start=234.6s stop=237.6s speaker_SPEAKER_01\n",
      "start=234.6s stop=235.5s speaker_SPEAKER_00\n",
      "start=239.8s stop=239.9s speaker_SPEAKER_02\n",
      "start=239.9s stop=240.0s speaker_SPEAKER_00\n",
      "start=240.0s stop=240.4s speaker_SPEAKER_02\n",
      "start=240.4s stop=240.5s speaker_SPEAKER_00\n",
      "start=244.0s stop=245.6s speaker_SPEAKER_00\n",
      "start=245.1s stop=245.3s speaker_SPEAKER_02\n",
      "start=250.3s stop=252.7s speaker_SPEAKER_01\n",
      "start=255.2s stop=258.0s speaker_SPEAKER_01\n",
      "start=258.6s stop=260.2s speaker_SPEAKER_01\n",
      "start=261.8s stop=262.2s speaker_SPEAKER_00\n",
      "start=263.8s stop=266.3s speaker_SPEAKER_00\n",
      "start=266.7s stop=266.9s speaker_SPEAKER_00\n",
      "start=269.7s stop=275.0s speaker_SPEAKER_01\n",
      "start=275.9s stop=276.3s speaker_SPEAKER_02\n",
      "start=277.4s stop=277.7s speaker_SPEAKER_02\n",
      "start=279.3s stop=280.2s speaker_SPEAKER_02\n",
      "start=290.6s stop=291.0s speaker_SPEAKER_02\n",
      "start=293.3s stop=296.0s speaker_SPEAKER_01\n",
      "start=298.2s stop=298.5s speaker_SPEAKER_02\n",
      "start=299.4s stop=302.0s speaker_SPEAKER_01\n",
      "start=305.6s stop=306.0s speaker_SPEAKER_00\n",
      "start=310.0s stop=311.9s speaker_SPEAKER_00\n",
      "start=310.1s stop=310.7s speaker_SPEAKER_02\n",
      "start=310.7s stop=311.0s speaker_SPEAKER_01\n",
      "start=312.8s stop=313.3s speaker_SPEAKER_00\n",
      "start=313.7s stop=313.7s speaker_SPEAKER_00\n",
      "start=315.2s stop=318.7s speaker_SPEAKER_00\n",
      "start=315.3s stop=315.8s speaker_SPEAKER_02\n",
      "start=319.5s stop=322.3s speaker_SPEAKER_00\n",
      "start=322.5s stop=322.8s speaker_SPEAKER_02\n",
      "start=323.4s stop=323.7s speaker_SPEAKER_00\n",
      "start=323.7s stop=324.2s speaker_SPEAKER_02\n",
      "start=323.7s stop=323.9s speaker_SPEAKER_00\n",
      "start=330.1s stop=330.2s speaker_SPEAKER_02\n",
      "start=332.1s stop=334.9s speaker_SPEAKER_02\n",
      "start=335.0s stop=335.2s speaker_SPEAKER_02\n",
      "start=335.8s stop=336.0s speaker_SPEAKER_02\n",
      "start=336.1s stop=336.3s speaker_SPEAKER_02\n",
      "start=338.6s stop=339.3s speaker_SPEAKER_02\n",
      "start=341.5s stop=342.8s speaker_SPEAKER_02\n",
      "start=343.6s stop=344.2s speaker_SPEAKER_02\n",
      "start=365.7s stop=366.1s speaker_SPEAKER_02\n",
      "start=369.6s stop=370.1s speaker_SPEAKER_02\n",
      "start=379.5s stop=380.3s speaker_SPEAKER_00\n",
      "start=382.2s stop=383.5s speaker_SPEAKER_00\n",
      "start=382.4s stop=383.2s speaker_SPEAKER_02\n",
      "start=384.3s stop=384.4s speaker_SPEAKER_02\n",
      "start=385.8s stop=386.3s speaker_SPEAKER_00\n",
      "start=386.4s stop=386.7s speaker_SPEAKER_00\n",
      "start=388.0s stop=390.2s speaker_SPEAKER_00\n",
      "start=391.0s stop=391.9s speaker_SPEAKER_00\n",
      "start=393.6s stop=395.5s speaker_SPEAKER_01\n",
      "start=399.1s stop=400.7s speaker_SPEAKER_01\n",
      "start=399.2s stop=399.3s speaker_SPEAKER_02\n",
      "start=399.3s stop=399.4s speaker_SPEAKER_00\n",
      "start=399.4s stop=399.6s speaker_SPEAKER_02\n",
      "start=401.4s stop=401.9s speaker_SPEAKER_00\n",
      "start=402.8s stop=403.1s speaker_SPEAKER_01\n",
      "start=403.4s stop=403.9s speaker_SPEAKER_00\n",
      "start=405.0s stop=407.8s speaker_SPEAKER_00\n",
      "start=408.3s stop=410.0s speaker_SPEAKER_00\n",
      "start=411.1s stop=411.8s speaker_SPEAKER_01\n",
      "start=413.2s stop=414.0s speaker_SPEAKER_01\n",
      "start=416.1s stop=417.1s speaker_SPEAKER_00\n",
      "start=418.8s stop=420.7s speaker_SPEAKER_01\n",
      "start=422.9s stop=423.4s speaker_SPEAKER_01\n",
      "start=423.1s stop=425.5s speaker_SPEAKER_00\n",
      "start=462.3s stop=463.0s speaker_SPEAKER_01\n",
      "start=463.8s stop=465.4s speaker_SPEAKER_01\n",
      "start=467.7s stop=468.2s speaker_SPEAKER_02\n",
      "start=469.8s stop=470.2s speaker_SPEAKER_01\n",
      "start=474.4s stop=475.1s speaker_SPEAKER_01\n",
      "start=484.0s stop=485.5s speaker_SPEAKER_01\n",
      "start=488.6s stop=490.7s speaker_SPEAKER_00\n",
      "start=491.6s stop=493.1s speaker_SPEAKER_00\n",
      "start=497.4s stop=500.4s speaker_SPEAKER_01\n",
      "start=511.9s stop=514.6s speaker_SPEAKER_01\n",
      "start=516.2s stop=516.9s speaker_SPEAKER_02\n",
      "start=518.1s stop=518.8s speaker_SPEAKER_01\n",
      "start=530.6s stop=530.6s speaker_SPEAKER_02\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"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\")\n",
    "\n",
    "# send pipeline to GPU (when available)\n",
    "import torch\n",
    "#pipeline.to(torch.device(\"cpu\"))\n",
    "\n",
    "# apply pretrained pipeline\n",
    "diarization = pipeline(\"Online_Lesson_Example.mp3\")\n",
    "\n",
    "# print the result\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n",
    "# start=0.2s stop=1.5s speaker_0\n",
    "# start=1.8s stop=3.9s speaker_1\n",
    "# start=4.2s stop=5.7s speaker_0\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EdControl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
